{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c8447c-afb5-46b5-9b44-023332d5d296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 00:03:09.945228: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-02 00:03:10.138419: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-02 00:03:10.138449: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-02 00:03:10.139483: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-02 00:03:10.224791: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Block 1\n",
    "# Imports\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import tokenize\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import tensorboard\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3532f1-59c9-4421-83cb-49c9dd54bad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 2\n",
    "# Loader\n",
    "\n",
    "\n",
    "class Loader:\n",
    "    def __init__(self, problems_path, submissions_dir, log_dir, max_length_input, max_length_output, batch_size):\n",
    "        self.problems_path = problems_path\n",
    "        self.submissions_dir = submissions_dir\n",
    "        self.max_length_input = max_length_input\n",
    "        self.max_length_output = max_length_output\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.problem_tokenizer = Tokenizer(filters='')\n",
    "        self.solution_tokenizer = Tokenizer(filters='', oov_token='UNK')\n",
    "        self.dataset = None\n",
    "        \n",
    "        self.writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "    def _load_problems_and_solutions(self):\n",
    "        # Load problems\n",
    "        with open(self.problems_path, 'r') as problems_file:\n",
    "            problems_list = json.load(problems_file)\n",
    "        raw_problems = {}\n",
    "        \n",
    "        for problem in problems_list:\n",
    "            problem_id = problem['problem_id']\n",
    "            concatenated_problem = \"XXSTATEMENT {} XXINPUT {} XXOUTPUT {} XXNOTES {} XXEXAMPLES {}\".format(\n",
    "                problem.get('problem_statement', ''),\n",
    "                problem.get('problem_input', ''),\n",
    "                problem.get('problem_output', ''),\n",
    "                problem.get('problem_notes', ''),\n",
    "                problem.get('examples', '')\n",
    "            )\n",
    "            raw_problems[problem_id] = concatenated_problem\n",
    "            \n",
    "        # Load solutions\n",
    "        raw_solutions = [[] for _ in range(len(raw_problems) * 2)] # Estimate allows us to delete up to half\n",
    "        submissions = glob.glob(os.path.join(self.submissions_dir, \"*.py\"))\n",
    "        \n",
    "        for submission_path in submissions:\n",
    "            problem_number = int(re.findall(r'^\\d+', os.path.basename(submission_path))[0])\n",
    "            with open(submission_path, \"r\") as f:\n",
    "                solutionList = []\n",
    "                for token in tokenize.generate_tokens(f.readline):\n",
    "                    solutionList.append(token.string)\n",
    "                raw_solutions[problem_number].append(solutionList)\n",
    "        \n",
    "        # Flatten problems and solutions\n",
    "        problems = []\n",
    "        solutions = []\n",
    "        for problem_id, solution_set in enumerate(raw_solutions):\n",
    "            if solution_set:\n",
    "                for solution in solution_set:\n",
    "                    problems.append(raw_problems[problem_id])\n",
    "                    solutions.append(solution)\n",
    "\n",
    "        return problems, solutions\n",
    "\n",
    "    def tokenize_and_pad(self, problems, solutions):\n",
    "        self.problem_tokenizer.fit_on_texts(problems)\n",
    "        self.solution_tokenizer.fit_on_texts(solutions)\n",
    "\n",
    "        problem_sequences = self.problem_tokenizer.texts_to_sequences(problems)\n",
    "        solution_sequences = self.solution_tokenizer.texts_to_sequences(solutions)\n",
    "\n",
    "        problems_padded = pad_sequences(problem_sequences, padding='post', maxlen=self.max_length_input)\n",
    "        solutions_padded = pad_sequences(solution_sequences, padding='post', maxlen=self.max_length_output)\n",
    "        \n",
    "        return problems_padded, solutions_padded\n",
    "    \n",
    "    def log_vocabulary(self):\n",
    "        with self.writer.as_default():\n",
    "            for word, index in self.problem_tokenizer.word_index.items():\n",
    "                tf.summary.text(name=\"Problem Vocabulary\", data=f\"{word}: {index}\", step=0)\n",
    "\n",
    "            for word, index in self.solution_tokenizer.word_index.items():\n",
    "                tf.summary.text(name=\"Solution Vocabulary\", data=f\"{word}: {index}\", step=0)\n",
    "\n",
    "            self.writer.flush()\n",
    "    \n",
    "    def _create_tf_dataset(self, problem_padded, solution_padded):\n",
    "        # Prepare decoder input (shifted solution)\n",
    "        decoder_input = tf.pad(solution_padded, [[0, 0], [1, 0]])[:, :-1]  # Shift left\n",
    "\n",
    "        # Ground truth\n",
    "        target = solution_padded\n",
    "\n",
    "        # Create the dataset\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(((problem_padded, decoder_input), target))\n",
    "        \n",
    "        return dataset.shuffle(buffer_size=1024).batch(self.batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    \n",
    "    def _log_dataset_samples(self, problem_padded, solution_padded):\n",
    "        with self.writer.as_default():\n",
    "            for i, (problem, solution) in enumerate(zip(problem_padded, solution_padded)):\n",
    "                if i >= 5:  # Log 5 samples\n",
    "                    break\n",
    "                \n",
    "                # Convert padded sequences back to text\n",
    "                problem_text = self.problem_tokenizer.sequences_to_texts([problem])\n",
    "                solution_text = self.solution_tokenizer.sequences_to_texts([solution])\n",
    "\n",
    "                # Truncate texts\n",
    "                #max_display_length = 1024\n",
    "                #problem_text = (problem_text[:max_display_length] + '...') if len(problem_text) > max_display_length else problem_text\n",
    "                #solution_text = (solution_text[:max_display_length] + '...') if len(solution_text) > max_display_length else solution_text\n",
    "\n",
    "                # Log to TensorBoard\n",
    "                tf.summary.text(name=f\"Problem_{i}\", data=problem_text, step=0)\n",
    "                tf.summary.text(name=f\"Solution_{i}\", data=solution_text, step=0)\n",
    "\n",
    "            self.writer.flush()\n",
    "            \n",
    "    def load_data(self):\n",
    "        problems, solutions = self._load_problems_and_solutions()\n",
    "\n",
    "        problems_padded, solutions_padded = self.tokenize_and_pad(problems, solutions)\n",
    "        self._log_dataset_samples(problems_padded, solutions_padded)\n",
    "        self.dataset = self._create_tf_dataset(problems_padded, solutions_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0ef91d-0806-4046-a111-f1916d98f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 3\n",
    "# Positional Encoder\n",
    "\n",
    "def positional_encoder(seq_length, dim):\n",
    "    # Generate positions for each element\n",
    "    positions = tf.range(seq_length, dtype=tf.float32)[..., tf.newaxis]\n",
    "\n",
    "    # Create a range for the dimensions and compute division terms\n",
    "    # Uses geometric progression with a base of 10,000; the rate depends on the dimension\n",
    "    i = tf.range(dim, dtype=tf.float32)\n",
    "    div_terms = 1 / tf.pow(10000.0, (2 * (i // 2)) / tf.cast(dim, tf.float32))\n",
    "\n",
    "    # Calculate odd/even sinusoidal encodings\n",
    "    angle_rates = positions * div_terms\n",
    "    sine = tf.sin(angle_rates[:, 0::2])\n",
    "    cosine = tf.cos(angle_rates[:, 1::2])\n",
    "\n",
    "    # Interlace and reshape\n",
    "    pos_encoding = tf.reshape(tf.concat([sine, cosine], axis=-1), [1, seq_length, dim])\n",
    "\n",
    "    return pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d505a2d-a02c-4bc5-9ca5-7555f9418fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 4\n",
    "# Encoder/Decoder Layer classes\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, dim_ff, num_heads, dropout_rate, name=\"EncoderLayer\"):\n",
    "        super(EncoderLayer, self).__init__(name=name)\n",
    "\n",
    "        # Multi-Head Self-Attention layer\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)\n",
    "\n",
    "        # Feed-Forward Network Layers\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dim_ff, activation='relu', kernel_initializer='he_normal', name=\"encoder_ffn_dense1\"),\n",
    "            tf.keras.layers.Dense(dim, kernel_initializer='he_normal', name=\"encoder_ffn_dense2\")\n",
    "        ], name=\"encoder_ffn\")\n",
    "\n",
    "        # Normalization Layers\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=\"encoder_layernorm1\")\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=\"encoder_layernorm2\")\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout_mha = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout_ffn = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        # Self-Attention\n",
    "        attn_output = self.mha(x, x)\n",
    "        attn_output = self.dropout_mha(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # Residual connection\n",
    "\n",
    "        # Feed-Forward Network\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout_ffn(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # Residual connection\n",
    "\n",
    "        return out2\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(EncoderLayer, self).get_config()\n",
    "        mha_config = self.mha.get_config()\n",
    "        config.update({\n",
    "            \"dim_ff\": self.ffn.layers[0].units,\n",
    "            \"num_heads\": mha_config['num_heads'], \n",
    "            \"key_dim\": mha_config['key_dim'], \n",
    "            \"dropout_rate\": self.dropout_mha.rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, dim_ff, num_heads, dropout_rate, name=\"DecoderLayer\"):\n",
    "        super(DecoderLayer, self).__init__(name=name)\n",
    "\n",
    "        # Self-Attention and Cross-Attention layers\n",
    "        self.mha1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)\n",
    "        self.mha2 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)\n",
    "\n",
    "        # Feed Forward Network Layers\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dim_ff, activation='relu', kernel_initializer='he_normal', name=\"decoder_ffn_dense1\"),\n",
    "            tf.keras.layers.Dense(dim, kernel_initializer='he_normal', name=\"decoder_ffn_dense2\")\n",
    "        ], name=\"decoder_ffn\")\n",
    "\n",
    "        # Normalization Layers\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=\"decoder_layernorm1\")\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=\"decoder_layernorm2\")\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=\"decoder_layernorm3\")\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout_self_attn = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout_cross_attn = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout_ffn = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, enc_output, training=False, look_ahead_mask=None, padding_mask=None):\n",
    "        # Self-Attention\n",
    "        attn1_output = self.mha1(x, x, attention_mask=look_ahead_mask)\n",
    "        attn1_output = self.dropout_self_attn(attn1_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn1_output)  # Residual connection\n",
    "\n",
    "        # Cross-Attention\n",
    "        attn2_output = self.mha2(out1, enc_output, attention_mask=padding_mask)\n",
    "        attn2_output = self.dropout_cross_attn(attn2_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + attn2_output)  # Residual connection\n",
    "\n",
    "        # Feed-Forward Network\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout_ffn(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # Residual connection\n",
    "\n",
    "        return out3\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(DecoderLayer, self).get_config()\n",
    "        mha1_config = self.mha1.get_config()  # Won't work if mha1 and mha2 are different\n",
    "        config.update({\n",
    "            \"dim_ff\": self.ffn.layers[0].units,\n",
    "            \"num_heads\": mha1_config['num_heads'], \n",
    "            \"key_dim\": mha1_config['key_dim'], \n",
    "            \"dropout_rate\": self.dropout_self_attn.rate\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bcb9091-5ff0-4c54-89c8-ee0a5463416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 5\n",
    "# Transformer\n",
    "\n",
    "class TransformerEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, dim_ff, key_dim, num_heads, num_layers, dropout_rate, name=\"TransformerEncoder\"):\n",
    "        super(TransformerEncoder, self).__init__(name=name)\n",
    "        self.num_layers = num_layers\n",
    "        self.enc_layers = [EncoderLayer(dim, dim_ff, num_heads, dropout_rate, name=f\"encoder_layer_{i}\") for i in range(num_layers)]\n",
    "\n",
    "    def call(self, x: tf.Tensor, training=False) -> tf.Tensor:\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x, training=training)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, dim_ff, key_dim, num_heads, num_layers, dropout_rate, name=\"TransformerDecoder\"):\n",
    "        super(TransformerDecoder, self).__init__(name=name)\n",
    "        self.num_layers = num_layers\n",
    "        self.dec_layers = [DecoderLayer(dim, dim_ff, num_heads, dropout_rate, name=f\"decoder_layer_{i}\") for i in range(num_layers)]\n",
    "\n",
    "    def call(self, x: tf.Tensor, enc_output: tf.Tensor, training=False) -> tf.Tensor:\n",
    "        for layer in self.dec_layers:\n",
    "            x = layer(x, enc_output, training=training)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, dim, dim_ff, key_dim, problem_vocab_size, solution_vocab_size, num_heads, num_layers, dropout_rate):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.dim = dim\n",
    "        \n",
    "        # Separate embedding for input and output\n",
    "        self.problem_embedding_layer = tf.keras.layers.Embedding(problem_vocab_size, dim)\n",
    "        self.solution_embedding_layer = tf.keras.layers.Embedding(solution_vocab_size, dim)\n",
    "\n",
    "        self.encoder = TransformerEncoder(dim, dim_ff, key_dim, num_heads, num_layers, dropout_rate, name=\"encoder\")\n",
    "        self.decoder = TransformerDecoder(dim, dim_ff, key_dim, num_heads, num_layers, dropout_rate, name=\"decoder\")\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(solution_vocab_size, name=\"output_layer\")\n",
    "\n",
    "    def call(self, encoder_input, decoder_input, training=False):\n",
    "        encoder_emb = self.problem_embedding_layer(encoder_input)\n",
    "        decoder_emb = self.solution_embedding_layer(decoder_input)\n",
    "\n",
    "        seq_length_enc = tf.shape(encoder_input)[1]\n",
    "        seq_length_dec = tf.shape(decoder_input)[1]\n",
    "        pos_encoding_enc = positional_encoder(seq_length_enc, self.dim)\n",
    "        pos_encoding_dec = positional_encoder(seq_length_dec, self.dim)\n",
    "\n",
    "        encoder_emb += pos_encoding_enc\n",
    "        decoder_emb += pos_encoding_dec\n",
    "\n",
    "        encoder_output = self.encoder(encoder_emb, training=training)\n",
    "        decoder_output = self.decoder(decoder_emb, encoder_output, training=training)\n",
    "\n",
    "        final_output = self.final_layer(decoder_output)\n",
    "\n",
    "        return final_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc04145d-725e-4db0-a9a6-ab2682e60890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 6\n",
    "# Build and Compile\n",
    "\n",
    "def build_and_compile(dim, dim_ff, key_dim, nhead, num_layers, problem_vocab_size, solution_vocab_size, dropout_rate, learning_rate=1e-4):\n",
    "    # Define model inputs\n",
    "    encoder_input = tf.keras.Input(shape=(None,), dtype='int32', name='encoder_input')\n",
    "    decoder_input = tf.keras.Input(shape=(None,), dtype='int32', name='decoder_input')\n",
    "\n",
    "    # Initialize and call the Transformer\n",
    "    transformer = Transformer(dim, dim_ff, key_dim, problem_vocab_size, solution_vocab_size, nhead, num_layers, dropout_rate)\n",
    "    final_output = transformer(encoder_input, decoder_input)\n",
    "\n",
    "    # Create the model\n",
    "    model = tf.keras.Model(inputs=[encoder_input, decoder_input], outputs=final_output)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c79e4070-2bbe-423d-8228-4e9aa08347d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 7\n",
    "# Define Training Steps\n",
    "\n",
    "def calculate_loss(model_output, tokenized_code, mask):\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(tokenized_code, model_output, from_logits=True)\n",
    "    loss *= mask  # Apply mask\n",
    "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, optimizer, tokenized_question, tokenized_code, clip_norm=10.0):\n",
    "    with tf.GradientTape() as tape:\n",
    "        model_output = model([tokenized_question, tokenized_code], training=True)\n",
    "\n",
    "        # Mask PAD tokens\n",
    "        mask = tf.cast(tf.math.logical_not(tf.math.equal(tokenized_code, 0)), dtype=model_output.dtype)\n",
    "        \n",
    "        # Calculate loss\n",
    "        average_loss = calculate_loss(model_output, tokenized_code, mask)\n",
    "\n",
    "    # Compute and clip gradients\n",
    "    gradients = tape.gradient(average_loss, model.trainable_variables)\n",
    "    clipped_gradients, _ = tf.clip_by_global_norm(gradients, clip_norm)\n",
    "\n",
    "    # Apply gradients to update model weights\n",
    "    optimizer.apply_gradients(zip(clipped_gradients, model.trainable_variables))\n",
    "\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d03c601c-7456-48fe-8bbc-bbef9a8a469d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "33/33 [==============================] - 32s 284ms/step - loss: 7.6988 - accuracy: 0.1883\n",
      "Epoch 2/8\n",
      "33/33 [==============================] - 8s 242ms/step - loss: 7.4619 - accuracy: 0.0651\n",
      "Epoch 3/8\n",
      "33/33 [==============================] - 8s 232ms/step - loss: 7.4693 - accuracy: 0.0084\n",
      "Epoch 4/8\n",
      "33/33 [==============================] - 8s 245ms/step - loss: 7.4318 - accuracy: 0.0084\n",
      "Epoch 5/8\n",
      "33/33 [==============================] - 8s 243ms/step - loss: 7.4161 - accuracy: 0.0084\n",
      "Epoch 6/8\n",
      "33/33 [==============================] - 8s 246ms/step - loss: 7.4279 - accuracy: 0.0084\n",
      "Epoch 7/8\n",
      "33/33 [==============================] - 8s 233ms/step - loss: 7.4290 - accuracy: 0.0084\n",
      "Epoch 8/8\n",
      "33/33 [==============================] - 8s 234ms/step - loss: 7.4281 - accuracy: 0.0084\n",
      "INFO:tensorflow:Assets written to: /workspace/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /workspace/assets\n"
     ]
    }
   ],
   "source": [
    "# Block 8\n",
    "# Execution\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths to data\n",
    "    problems_path = \"/workspace/Training_Data/A_Problems.json\"\n",
    "    submissions_dir = \"/workspace/Training_Data/A_Submissions\"\n",
    "    log_dir = \"/workspace/logs\"\n",
    "\n",
    "    #problems_path = \"C:/AIClub/Training_Data_Cleaned/A_Problems.json\"\n",
    "    #submissions_dir = \"C:/AIClub/Training_Data_Cleaned/A_Submissions\"\n",
    "    #log_dir = \"C:/AIClub/logs\"\n",
    "\n",
    "    # Set hyperparameters\n",
    "    dim = 512\n",
    "    dim_ff = dim * 4\n",
    "    num_layers = 6\n",
    "    num_heads = 8\n",
    "    key_dim = dim // num_heads\n",
    "\n",
    "    max_length_input = 530 # Set to cover about 85% of inputs\n",
    "    max_length_output = 50 # Set to cover 100% of ground truth outputs\n",
    "    dropout_rate = 0.1\n",
    "\n",
    "    batch_size = 16\n",
    "    learning_rate = 0.001\n",
    "    epochs = 8\n",
    "\n",
    "    assert dim % num_heads == 0, \"dim % num_heads != 0\"\n",
    "\n",
    "    # Initialize the Loader\n",
    "    loader = Loader(problems_path, submissions_dir, log_dir, max_length_input, max_length_output, batch_size)\n",
    "    loader.load_data()\n",
    "    problem_vocab_size = len(loader.problem_tokenizer.word_index) + 1\n",
    "    solution_vocab_size = len(loader.solution_tokenizer.word_index) + 1\n",
    "    \n",
    "    # Build the model\n",
    "    model = build_and_compile(dim, dim_ff, key_dim, num_heads, num_layers, problem_vocab_size, solution_vocab_size, dropout_rate, learning_rate)\n",
    "\n",
    "    # Setup TensorBoard callback\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(loader.dataset, epochs=epochs, callbacks=[tensorboard_callback]) # history variable unused...\n",
    "    \n",
    "    \"\"\"\n",
    "    optimizer = model.optimizer\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Start of Epoch {epoch+1}\")\n",
    "\n",
    "        # Iterate over the batches of the dataset.\n",
    "        for step, ((tokenized_question, tokenized_code), target) in enumerate(loader.dataset):\n",
    "            # Call the custom train_step\n",
    "            loss = train_step(model, optimizer, tokenized_question, tokenized_code[:, :-1])\n",
    "\n",
    "            # Log every 200 batches\n",
    "            if step % 200 == 0:\n",
    "                print(f\"Epoch {epoch+1}, Step {step}, Loss: {loss.numpy()}\")\n",
    "\n",
    "        print(f\"End of Epoch {epoch+1}, Loss: {loss.numpy()}\")\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save the model\n",
    "    model.save(\"/workspace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "112669f0-144f-4c82-ae0d-9d5f93ee4fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 741ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 39 190 126 429 882  55 883 407 212  38], shape=(10,), dtype=int32)\n",
      "tf.Tensor([  0 118  10  13  11   7   2   2  23  15], shape=(10,), dtype=int32)\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Predicted sequence:  [[35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35]\n",
      " [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35]\n",
      " [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35]\n",
      " [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35]\n",
      " [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35]\n",
      " [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35]\n",
      " [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35]\n",
      " [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35]\n",
      " [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35]\n",
      " [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35]\n",
      " [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35]\n",
      " [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35]\n",
      " [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35]\n",
      " [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35]\n",
      " [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35]\n",
      " [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      "  35 35]]\n",
      "Predicted text:  ['* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *', '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *', '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *', '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *', '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *', '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *', '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *', '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *', '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *', '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *', '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *', '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *', '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *', '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *', '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *', '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *']\n"
     ]
    }
   ],
   "source": [
    "# Block 10\n",
    "# Evaluation Class\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, model, loader):\n",
    "        self.model = model\n",
    "        self.loader = loader\n",
    "\n",
    "    def plot_loss(self, history):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.title('Loss Curve')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_token_probabilities(self, token_index, n_samples):\n",
    "        # Get n_samples from the dataset\n",
    "        for (encoder_input, decoder_input), _ in self.loader.dataset.take(n_samples):\n",
    "            prediction = self.model.predict([encoder_input, decoder_input])\n",
    "            token_logits = prediction[0, token_index]\n",
    "\n",
    "            # Convert logits to probabilities\n",
    "            token_probabilities = tf.nn.softmax(token_logits).numpy()\n",
    "\n",
    "            sorted_indices = np.argsort(token_probabilities)[::-1]\n",
    "            sorted_probabilities = token_probabilities[sorted_indices]\n",
    "\n",
    "            plt.figure(figsize=(20, 5))\n",
    "            plt.bar(range(len(sorted_probabilities)), sorted_probabilities)\n",
    "            plt.xlabel('Word Indices (sorted by probability)')\n",
    "            plt.ylabel('Probability')\n",
    "            plt.title(f'Word Prediction Probabilities for Token {token_index}')\n",
    "            plt.show()\n",
    "\n",
    "    def generate_sample_predictions(self, n_samples=1):\n",
    "        # Get n_samples from the dataset\n",
    "        for (encoder_input, decoder_input), _ in self.loader.dataset.take(n_samples):\n",
    "            print(encoder_input[1][:10])\n",
    "            print(decoder_input[1][:10])\n",
    "            prediction = self.model.predict([encoder_input, decoder_input])\n",
    "            predicted_sequence = np.argmax(prediction, axis=-1)\n",
    "            predicted_text = self.loader.solution_tokenizer.sequences_to_texts(predicted_sequence)\n",
    "\n",
    "            print(\"Predicted sequence: \", predicted_sequence)\n",
    "            print(\"Predicted text: \", predicted_text)\n",
    "\n",
    "    def evaluate(self, command, *args, **kwargs):\n",
    "        if command == 'loss':\n",
    "            self.plot_loss(*args, **kwargs)\n",
    "        elif command == 'token_prob':\n",
    "            self.plot_token_probabilities(*args, **kwargs)\n",
    "        elif command == 'sample_pred':\n",
    "            self.generate_sample_predictions(*args, **kwargs)\n",
    "        else:\n",
    "            print(f\"Unknown command: {command}\")\n",
    "\n",
    "# Load the model if it's not\n",
    "model = tf.keras.models.load_model('/workspace')\n",
    "\n",
    "# Uncomment what you want to run\n",
    "evaluator = Evaluator(model, loader)\n",
    "#evaluator.evaluate('loss', history)\n",
    "evaluator.evaluate('token_prob', token_index=10, n_samples=1)\n",
    "evaluator.evaluate('sample_pred', n_samples=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63cd5725-9961-414f-a052-207233613908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6a800b565bec91f8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6a800b565bec91f8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8088;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs --host localhost --port 8088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe4a14-9e47-49f1-ba76-b33996e4e827",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_function():\n",
    "    tf.print(\"Test message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c4c276-c445-4cdd-8576-717f90d732ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(loader.problem_tokenizer.word_index) + 1\n",
    "len(loader.solution_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa2755c7-0765-457e-8843-b235dc3a30df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
