# Transformer NLP Model for Coding Questions

Welcome to the repository! This project focuses on natural language processing (NLP) and sequence-to-sequence (seq-to-seq) translation, specifically designed to take in LeetCode-style coding questions and produce corresponding code answers.  However, I've designed it to be fully modular in every way possible, intending for it to be used for many research projects to come.

## Overview

- **Classic Transformer Architecture**: Utilizes a classic transformer architecture.
- **NLP & Seq-to-Seq Translation**: Excels at natural language processing tasks, converting text-based coding questions into executable code.
- **Full-Scale Implementation**: Built to be full-scale and match the quality of large-scale LLMs.

## Features

- **Full Modularity**: While the current implementation is mostly a classic transformer, every bit of how it works is object-oriented and can be swapped out easily.
- **Coding Question Handling**: Designed specifically to understand and generate solutions for coding questions.  The data-preprocessing files, which are hosted in the repository, are designed to look and deal with all sorts of raw code from the internet.

## Getting Started

To get started with the project, clone the repository and follow the setup instructions provided in the `setup` section.

```bash
git clone https://github.com/BreckEmert/Coding-SLM
cd Coding-SLM
```