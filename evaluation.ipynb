{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b33858-3efc-45b9-ac60-e9b171da87d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 10\n",
    "# Evaluation Class\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, model, loader):\n",
    "        self.model = model\n",
    "        self.loader = loader\n",
    "\n",
    "    def plot_loss(self, history):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.title('Loss Curve')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_token_probabilities(self, token_index, n_samples=1):\n",
    "        # Take one batch from the dataset\n",
    "        for (encoder_input, decoder_input), _ in self.loader.dataset.take(1):\n",
    "            # Slice the batch down to n_samples\n",
    "            encoder_input = encoder_input[:n_samples]\n",
    "            decoder_input = decoder_input[:n_samples]\n",
    "\n",
    "            # Predict on the sliced inputs\n",
    "            predictions = self.model.predict([encoder_input, decoder_input])\n",
    "\n",
    "            for sample_idx in range(n_samples):\n",
    "                # For each sample, extract token logits and convert to probabilities\n",
    "                token_logits = predictions[sample_idx, token_index, :]\n",
    "                token_probabilities = tf.nn.softmax(token_logits).numpy()\n",
    "                sorted_indices = np.argsort(token_probabilities)[::-1]\n",
    "                sorted_probabilities = token_probabilities[sorted_indices]\n",
    "\n",
    "                # Plotting\n",
    "                plt.figure(figsize=(20, 5))\n",
    "                plt.bar(range(len(sorted_probabilities)), sorted_probabilities)\n",
    "                plt.xlabel('Word Indices (sorted by probability)')\n",
    "                plt.ylabel('Probability')\n",
    "                plt.title(f'Word Prediction Probabilities for Token {token_index} in Sample {sample_idx+1}')\n",
    "                plt.show()\n",
    "\n",
    "    def generate_training_predictions(self, n_samples=1):\n",
    "        # Take one batch from the dataset\n",
    "        for (encoder_inputs, decoder_inputs), _ in self.loader.dataset.take(1):\n",
    "            # Slice the batch down to n_samples\n",
    "            encoder_inputs = encoder_inputs[:n_samples]\n",
    "            decoder_inputs = decoder_inputs[:n_samples]\n",
    "\n",
    "            # Predict on the sliced inputs\n",
    "            predictions = self.model.predict([encoder_inputs, decoder_inputs])\n",
    "            predicted_sequences = np.argmax(predictions, axis=-1)\n",
    "\n",
    "            # Convert sequences to text\n",
    "            encoder_inputs = encoder_inputs = encoder_inputs.numpy() # Can factor this later\n",
    "            input_texts = self.loader.problem_tokenizer.sequences_to_texts(encoder_inputs)\n",
    "            predicted_texts = self.loader.solution_tokenizer.sequences_to_texts(predicted_sequences)\n",
    "            \n",
    "            # Print each prediction in the slice\n",
    "            for i, predicted_text in enumerate(predicted_texts):\n",
    "                print(f\"Sample {i + 1}:\") \n",
    "                print(\"Input sequence [:250]:\", input_texts[i][:250])\n",
    "                print(\"Predicted sequence:\", predicted_sequences[i])\n",
    "                print(\"Predicted text:\", predicted_text, \"\\n\")\n",
    "    \n",
    "    def generate_manual_predictions(self, input_text):\n",
    "        # Tokenize the input string\n",
    "        input_seq = self.loader.problem_tokenizer.texts_to_sequences([input_text])\n",
    "        input_padded = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=self.loader.max_length_input, padding='post')\n",
    "\n",
    "        # Prepare the decoder input\n",
    "        start_token_index = self.loader.solution_tokenizer.word_index.get('[START]', 1)  # Fallback to 1 if not found\n",
    "        decoder_input = np.array([[start_token_index]])\n",
    "        \n",
    "        # Generate and interpret the prediction\n",
    "        predictions = self.model.predict([input_padded, decoder_input])\n",
    "        predicted_sequence = np.argmax(predictions, axis=-1)[0]\n",
    "        predicted_text = self.loader.solution_tokenizer.sequences_to_texts([predicted_sequence])\n",
    "        \n",
    "        # Print the output\n",
    "        print(\"Input text:\", input_text)\n",
    "        print(\"Predicted text:\", predicted_text[0])\n",
    "\n",
    "    def evaluate(self, command, *args, **kwargs):\n",
    "        if command == 'loss':\n",
    "            self.plot_loss(*args, **kwargs)\n",
    "        elif command == 'token_prob':\n",
    "            self.plot_token_probabilities(*args, **kwargs)\n",
    "        elif command == 'training_sample_pred':\n",
    "            self.generate_training_predictions(*args, **kwargs)\n",
    "        elif command == 'manual_sample_pred':\n",
    "            self.generate_manual_predictions(*args, **kwargs)\n",
    "        else:\n",
    "            print(f\"Unknown command: {command}\")\n",
    "\n",
    "# Load the model if it's not\n",
    "model = tf.keras.models.load_model('/workspace')\n",
    "\n",
    "# Uncomment what you want to run\n",
    "evaluator = Evaluator(model, loader)\n",
    "#evaluator.evaluate('loss', history)\n",
    "#evaluator.evaluate('token_prob', token_index=10, n_samples=3)\n",
    "evaluator.evaluate('training_sample_pred', n_samples=3)\n",
    "\n",
    "input_text = \"XXSTATEMENT Susie like squares.  When playing with one, she wants to know how many sides it has.  For each side of the square, print its length.  XXINPUT An object s, which is an integer representing the length of a side l.  XXOUTPUT Four copies of the length s\"\n",
    "evaluator.evaluate('manual_sample_pred', input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e907c7-c9fe-432c-9c3c-3169c6d556a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs --host localhost --port 8088"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
